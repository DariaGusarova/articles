# Non-Monotonic Sequential Text Generation

1. Link: https://arxiv.org/abs/1902.02192
2. Repository:  https://github.com/wellecks/nonmonotonic_text  

## Основная идея

Обычно модели для генерации теста используют предопределенный порядок, слева-направо, справа-налево или по дереву синтаксического разбора. Но хочется, чтобы не нужно было ничего предопределять, то есть модель бы генерировала некоторое слово, а затем запускался процесс генерации того, что должно быть слева от данного слова и того, что должно быть справа. 

Если формально, то есть некоторая последовательность слов, которая задает состояние, она соотвествует неполному бинарному дереву, читаемому сверху вниз слева направо, терминальные вершины обозначаются символом end, и есть действие, обозначаемое словом, которое будет записано в рассматриваемую вершину и соотвественно добавлено справа к текущему состоянию. Под политикой подразумеваем распределение над множеством возможных действий при условии текущего состояния. И именно ее нужно оптимизировать.

## Оптимизация

Есть roll-in политика и roll-out политика. С помощью первой происходит переход в текущее состояние, то есть семплируется текущее состояние, с помощью второй происходит оценка обучаемой политики. Как функцию оценки можно использовать MSE, например, но лучший результат показала метрика основанная на KL- дивергенции. Теоретически хочется оптимизировать математическое ожидание по предложению в корпусе, по номеру шага генерации, по полученному по roll-in политике состоянию метрику от вычиляемой политики и roll-out политики от данного состояния. На практике это слишком сложно, поэтому используется аппроксимация математические ожидания заменяются семплированием.

## Политика оракула

На нее заменяются roll-in и roll-out политики. Считаем, что состоянию на шаге t соотвествует некоторое подстрока исходной строки. Для нулевого состояния вся строка. Если подстрока пуста, то все вероятность сосредотачивается в символе end, иначе распределяется между элементами подстроки. Затем из полученного распределения семплируется слово и подстрока делится между детями вершины, соотвествующей состоянию, по этому слову.

В качестве распределения на элементах подстроки можно взять: равномерное, coaching oracle (равномерное перемноженное с текущей обучаемой политикой) и annealed coaching oracle (линеная комбинация равномерного и coaching oracle с коэффициентом перед равномерной составляющей линейно убывающим в процессе обучения), или детерминированный слева на право (то есть идти на лево нельзя никогда).

## Модель 

В качестве модели используется LSTM. На вход модели поступает последовательность состояний, а на выходе получается распределение над множеством возможных переходов (преобразованием скрытой переменной). Удобно, что можно легко добавить дополнительные данные, просто включить их в начальной состояние LSTM, например.

## Эксперименты

Первый эксперимент: генерация предложений, до этого происходило обучение на корпусе диалогов. Под новизной предполагается процент предложений, которых не было в корпусе, под уникальностью отношение числа различных предложений, к общему числу сгенерированных предложений, еще есть метрика среднея длина предложения и average span среднее число детей, не являющихся символом end, у вершины. Лидерами являются uniform и annealed, скорее даже второй, так как у него выше BLEU. Он генерирует более новый и хорошие предложения чем left-right метод.

Второй эксперимент: связан с дополнением предложения с пропусками в произвольных местах. Подход слева направо позволял так делать естественно только с последним словом, здесь же с произвольным. Для этого нужно только построить какой-либо непольное дерево по имеющимся словам и запустить модель.

Третий эксперимент: построение предложения по уже имеющимся словам. То есть некоторый набор слов, а точнее их эмбеддинги используются как стартовой состояние LSTM. Рассматриваюся метрики BLEU, F1 и exact matching. Если изучить вопрос в чем преимущество anneal, то окажется что его энтропия, в отличии от uniform и left-right долго остается довольно высокой, да и потом стабилизируется около значения около 0.8, в то время как у его конкурентов она быстро уходит к 0.4-0.5. То есть anneal сначала восстанавливает простую часть и только потом начинает достраивать сложные куски.
